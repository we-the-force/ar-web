<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>Image based tracking AR.js demo</title>
    <!-- import aframe and then ar.js with image tracking / location based features -->
    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>
    <script src="https://unpkg.com/aframe-transparent-video-shader@1.0.1/dist/aframe-transparent-video-shader.umd.js"></script>

    <!-- style for the loader -->
    <style>
      .arjs-loader {
        height: 100%;
        width: 100%;
        position: absolute;
        top: 0;
        left: 0;
        background-color: rgba(0, 0, 0, 0.8);
        z-index: 100;
        display: flex;
        justify-content: center;
        align-items: center;
      }
      #bgoverlay {
          position: absolute;
          width: 100%;
          height: 100%;
          top: 0;
          left: 0;
          background-color: #fff;
          z-index: 1;
      }
      #bgoverlay p {
          font-family:Arial, Helvetica, sans-serif;
          font-size: 23px;
          width: 100%;
          text-align: center;
          color: rgb(224, 46, 46);
          position: absolute;
          top: 50%;
          transform: translate(0, 11px);
      }
      .play-overlay {
          z-index: 99999;
          position: fixed;
          bottom: 50%;
          transform: translate(30px, 30px);
          right: 50%;
          box-sizing: border-box;
          width: 60px;
          height: 60px;
          border-radius: 50%;
          padding: 12px 24px;
          padding-bottom: 0px;
          background: rgb(224, 46, 46) url(play.png) center no-repeat;
          background-size: 40px 40px;
      }

      .play-overlay:hover {
          background: rgba(0, 0, 0, 0.2) url(play.png) center no-repeat;
          background-size: 40px 40px;
      }

      .arjs-loader div {
        text-align: center;
        font-size: 1.25em;
        color: white;
      }
    </style>
  </head>

  <body style="margin : 0px; overflow: hidden;">
    <!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->
    <div class="arjs-loader">
      <div>Loading, please wait...</div>
    </div>

    <!-- a-frame scene -->
    <a-scene
      vr-mode-ui="enabled: false;"
      renderer="logarithmicDepthBuffer: true;"
      embedded
      arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;">
      <!-- a-nft is the anchor that defines an Image Tracking entity -->
      <!-- on 'url' use the path to the Image Descriptors created before. -->
      <!-- the path should end with the name without the extension e.g. if file is trex.fset' the path should end with trex -->
      <a-assets>
      <img id="transpImage" crossorigin="anonymous" src="./dm.png">
<video id="vid" autoplay loop="true" src="lycra_vid.webm"></video>

      </a-assets>
      <a-nft
        type="nft"
        url="./tks"
        smooth="true"
        smoothCount="10"
        smoothTolerance=".01"
        smoothThreshold="5">
          <!-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -->
          <a-entity material="shader: transparent-video;" geometry="primitive: plane;
          width: 16;
          height: 9" src="#vid"  scale="10 10 10" position="0 0 -20"></a-entity>
          <a-entity
              gltf-model="url(./logowtf.glb)"
              scale="25 25 25"
              position="50 0 -300"
              rotation="-90 0 0"
              animation-mixer="clip: *;"
              material="color: red; roughness: 1; metalness: 0"
              >
          </a-entity>
          <a-entity
          gltf-model="./scene2.glb"
          scale="30 30 30"
              position="50 100 -200"
              rotation="0 0 0"
              animation-mixer="clip: *;"
          >
          </a-entity>
          <a-image position = "0 1.6 -1" width="6.3" scale="30 30 30" rotation="-90 0 0" animation="property: position; to: 1 8 -10; dur: 2000; easing: linear; loop: true" height="1" src="#transpImage" transparent="true" alpha-test="0.5"></a-image>
      </a-nft>
      <!-- static camera that moves according to the device movemenents -->
      <a-entity camera></a-entity>
    </a-scene>
    <a id="playButton" onclick="play('vid')">
        <div class="btn btn-primary play-overlay menu-overlay"></div>
    </a>
    <div id="bgoverlay">
        <p>Start</p>
    </div>
    <script>
        var sceneEl = document.querySelector('a-scene');
        var entity = sceneEl.querySelector('a-entity');
        console.log();
        vid.pause();

        function play(id) {
            vid.play();
            hideOrShow('playButton');
            hideOrShow("bgoverlay");

        }

        function hideOrShow(id) {
            var x = document.getElementById(id);
            if (x.style.display === "none") {
                x.style.display = "block";
            } else {
                x.style.display = "none";
            }
        }
    </script>
  </body>
</html>